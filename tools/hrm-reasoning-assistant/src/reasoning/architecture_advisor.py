"""
Architecture Advisor using Hierarchical Reasoning Model

Provides architectural guidance for AstraTrade development using HRM's
hierarchical reasoning capabilities to analyze complex architectural decisions.
"""

import torch
import os
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from pathlib import Path
import logging

from ..hrm.model import HierarchicalReasoningModel, HRMConfig
from .code_analyzer import CodeTokenizer

logger = logging.getLogger(__name__)


@dataclass
class ArchitecturalContext:
    """Context information for architectural decisions"""
    current_structure: Dict[str, Any]
    constraints: List[str]
    requirements: List[str]
    domain: str
    complexity_factors: List[str]


@dataclass
class ArchitecturalAdvice:
    """Architectural advice generated by HRM"""
    question: str
    analysis: str
    recommendations: List[str]
    trade_offs: List[Dict[str, str]]
    implementation_steps: List[str]
    reasoning_process: List[str]
    confidence: float
    alternative_approaches: List[str]


class ArchitectureAdvisor:
    """
    HRM-powered architecture advisor for AstraTrade development
    
    Uses hierarchical reasoning to analyze architectural questions and provide
    comprehensive guidance considering multiple factors and trade-offs.
    """
    
    def __init__(self, model_path: Optional[str] = None):
        self.tokenizer = CodeTokenizer()
        
        # Architecture-specific vocabulary extensions
        self.arch_vocab = {
            # Architectural patterns
            'microservices': 200, 'monolith': 201, 'layered': 202, 'hexagonal': 203,
            'event_driven': 204, 'cqrs': 205, 'saga': 206, 'repository': 207,
            
            # Quality attributes
            'scalability': 210, 'performance': 211, 'maintainability': 212,
            'reliability': 213, 'security': 214, 'usability': 215,
            
            # AstraTrade specific
            'trading_domain': 220, 'gamification_domain': 221, 'financial_domain': 222,
            'blockchain_integration': 223, 'real_time_processing': 224,
            
            # Decision factors
            'coupling': 230, 'cohesion': 231, 'complexity': 232, 'performance_impact': 233,
            'development_velocity': 234, 'operational_overhead': 235
        }
        
        # Extend tokenizer vocabulary
        self.tokenizer.vocab.update(self.arch_vocab)
        self.tokenizer.reverse_vocab = {v: k for k, v in self.tokenizer.vocab.items()}
        
        # Initialize HRM model
        self.config = HRMConfig(
            hidden_size=512,
            vocab_size=len(self.tokenizer.vocab),
            N=4,  # 4 high-level reasoning cycles for architecture
            T=6,  # 6 low-level steps per cycle
            use_stablemax=True
        )
        
        self.model = HierarchicalReasoningModel(self.config)
        
        if model_path and os.path.exists(model_path):
            self.model.load_state_dict(torch.load(model_path, map_location='cpu'))
            logger.info(f"Loaded architecture model from {model_path}")
        else:
            logger.info("Using untrained model for architecture advice")
    
    def get_advice(
        self, 
        question: str, 
        context_path: Optional[str] = None
    ) -> str:
        """
        Get architectural advice for a given question
        """
        logger.info(f"Analyzing architectural question: {question}")
        
        # Analyze context if provided
        context = self._analyze_context(context_path) if context_path else None
        
        # Tokenize the question with context
        tokens = self._tokenize_architectural_question(question, context)
        input_ids = torch.tensor([tokens], dtype=torch.long)
        
        # Run HRM reasoning
        self.model.eval()
        with torch.no_grad():
            output = self.model(input_ids, return_intermediate=True)
            
            # Extract reasoning information
            reasoning_analysis = self._analyze_architectural_reasoning(
                output['z_h'], 
                output['z_l'], 
                output.get('intermediate_states', [])
            )
        
        # Generate architectural advice
        advice = self._generate_architectural_advice(
            question=question,
            context=context,
            reasoning_analysis=reasoning_analysis
        )
        
        return self._format_advice(advice)
    
    def _analyze_context(self, context_path: str) -> ArchitecturalContext:
        """Analyze architectural context from codebase"""
        context_dir = Path(context_path)
        
        if not context_dir.exists():
            logger.warning(f"Context path {context_path} does not exist")
            return self._default_context()
        
        # Analyze current structure
        structure = self._analyze_directory_structure(context_dir)
        
        # Identify domain
        domain = self._identify_domain(context_dir)
        
        # Extract constraints and requirements
        constraints = self._extract_constraints(context_dir)
        requirements = self._extract_requirements(context_dir)
        complexity_factors = self._identify_complexity_factors(context_dir)
        
        return ArchitecturalContext(
            current_structure=structure,
            constraints=constraints,
            requirements=requirements,
            domain=domain,
            complexity_factors=complexity_factors
        )
    
    def _analyze_directory_structure(self, directory: Path) -> Dict[str, Any]:
        """Analyze directory structure for architectural patterns"""
        structure = {
            'domains': [],
            'services': [],
            'layers': [],
            'patterns': []
        }
        
        # Check for domain structure
        domains_path = directory / 'domains'
        if domains_path.exists():
            structure['domains'] = [d.name for d in domains_path.iterdir() if d.is_dir()]
            structure['patterns'].append('Domain-Driven Design')
        
        # Check for microservices
        services_path = directory / 'services'
        if services_path.exists():
            structure['services'] = [s.name for s in services_path.iterdir() if s.is_dir()]
            if len(structure['services']) > 1:
                structure['patterns'].append('Microservices')
        
        # Check for layered architecture
        common_layers = ['api', 'core', 'infrastructure', 'models']
        found_layers = [layer for layer in common_layers if (directory / layer).exists()]
        structure['layers'] = found_layers
        if len(found_layers) >= 3:
            structure['patterns'].append('Layered Architecture')
        
        # Check for event-driven patterns
        events_path = directory / 'infrastructure' / 'events'
        if events_path.exists():
            structure['patterns'].append('Event-Driven Architecture')
        
        return structure
    
    def _identify_domain(self, directory: Path) -> str:
        """Identify the primary domain from directory structure"""
        domain_indicators = {
            'trading': ['trading', 'trade', 'order', 'portfolio'],
            'gamification': ['gamification', 'game', 'achievement', 'leaderboard'],
            'financial': ['financial', 'payment', 'billing', 'subscription'],
            'social': ['social', 'user', 'community'],
            'nft': ['nft', 'token', 'blockchain']
        }
        
        # Count domain indicators in file/directory names
        domain_scores = {domain: 0 for domain in domain_indicators}
        
        for file_path in directory.rglob('*'):
            file_name = file_path.name.lower()
            for domain, indicators in domain_indicators.items():
                for indicator in indicators:
                    if indicator in file_name:
                        domain_scores[domain] += 1
        
        # Return domain with highest score
        return max(domain_scores, key=domain_scores.get) if max(domain_scores.values()) > 0 else 'unknown'
    
    def _extract_constraints(self, directory: Path) -> List[str]:
        """Extract architectural constraints from codebase"""
        constraints = []
        
        # Check for Docker constraints
        if (directory / 'docker-compose.yml').exists():
            constraints.append("Containerized deployment")
        
        # Check for database constraints
        if any(directory.glob('**/requirements.txt')):
            with open(next(directory.glob('**/requirements.txt')), 'r') as f:
                content = f.read()
                if 'postgresql' in content:
                    constraints.append("PostgreSQL database")
                if 'redis' in content:
                    constraints.append("Redis caching/messaging")
        
        # Check for blockchain constraints
        if any(directory.glob('**/*.cairo')):
            constraints.append("Starknet blockchain integration")
        
        # Check for real-time constraints
        if any('websocket' in f.name.lower() for f in directory.rglob('*')):
            constraints.append("Real-time communication requirements")
        
        return constraints
    
    def _extract_requirements(self, directory: Path) -> List[str]:
        """Extract functional requirements from codebase"""
        requirements = []
        
        # Extract from file names and content
        functional_areas = {
            'Authentication': ['auth', 'login', 'jwt'],
            'Trading Operations': ['trade', 'order', 'execute'],
            'User Management': ['user', 'account', 'profile'],
            'Gamification': ['achievement', 'leaderboard', 'xp'],
            'Financial Processing': ['payment', 'billing', 'subscription'],
            'Real-time Updates': ['websocket', 'streaming', 'live'],
            'API Integration': ['api', 'client', 'external']
        }
        
        for requirement, indicators in functional_areas.items():
            if any(
                any(indicator in file_path.name.lower() for indicator in indicators)
                for file_path in directory.rglob('*')
            ):
                requirements.append(requirement)
        
        return requirements
    
    def _identify_complexity_factors(self, directory: Path) -> List[str]:
        """Identify factors that add architectural complexity"""
        factors = []
        
        # Count domains
        domains_path = directory / 'domains'
        if domains_path.exists():
            domain_count = len([d for d in domains_path.iterdir() if d.is_dir()])
            if domain_count > 3:
                factors.append(f"Multiple domains ({domain_count})")
        
        # Count services
        services_path = directory / 'services'
        if services_path.exists():
            service_count = len([s for s in services_path.iterdir() if s.is_dir()])
            if service_count > 2:
                factors.append(f"Multiple services ({service_count})")
        
        # Check for external integrations
        integration_indicators = ['client', 'api', 'external', 'third_party']
        integration_files = [
            f for f in directory.rglob('*')
            if any(indicator in f.name.lower() for indicator in integration_indicators)
        ]
        if len(integration_files) > 3:
            factors.append("Multiple external integrations")
        
        # Check for async complexity
        async_files = [f for f in directory.rglob('*.py') if 'async' in f.read_text(errors='ignore')]
        if len(async_files) > 5:
            factors.append("Significant asynchronous processing")
        
        return factors
    
    def _default_context(self) -> ArchitecturalContext:
        """Return default context when path analysis fails"""
        return ArchitecturalContext(
            current_structure={'patterns': ['Unknown']},
            constraints=['Standard web architecture'],
            requirements=['Basic CRUD operations'],
            domain='unknown',
            complexity_factors=['Insufficient context']
        )
    
    def _tokenize_architectural_question(
        self, 
        question: str, 
        context: Optional[ArchitecturalContext]
    ) -> List[int]:
        """Tokenize architectural question with context"""
        tokens = [self.tokenizer.vocab['<START>']]
        
        # Add question tokens
        question_words = question.lower().split()
        for word in question_words:
            token = self.tokenizer.vocab.get(word, self.tokenizer.vocab['<UNK>'])
            tokens.append(token)
        
        # Add context tokens if available
        if context:
            # Add domain token
            domain_token = self.arch_vocab.get(f"{context.domain}_domain")
            if domain_token:
                tokens.append(domain_token)
            
            # Add pattern tokens
            for pattern in context.current_structure.get('patterns', []):
                pattern_key = pattern.lower().replace(' ', '_').replace('-', '_')
                pattern_token = self.arch_vocab.get(pattern_key)
                if pattern_token:
                    tokens.append(pattern_token)
            
            # Add complexity indicators
            if len(context.complexity_factors) > 2:
                tokens.append(self.arch_vocab.get('complexity', self.tokenizer.vocab['<UNK>']))
        
        tokens.append(self.tokenizer.vocab['<END>'])
        return tokens
    
    def _analyze_architectural_reasoning(
        self, 
        z_h: torch.Tensor, 
        z_l: torch.Tensor, 
        intermediate_states: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Analyze HRM reasoning for architectural decisions"""
        
        # Compute reasoning depth and complexity
        reasoning_depth = len(intermediate_states)
        
        # Calculate decision complexity based on state variations
        if len(intermediate_states) > 0:
            state_variations = []
            for i in range(1, len(intermediate_states)):
                prev_state = intermediate_states[i-1].get('hidden_state', torch.zeros(1))
                curr_state = intermediate_states[i].get('hidden_state', torch.zeros(1))
                if isinstance(prev_state, torch.Tensor) and isinstance(curr_state, torch.Tensor):
                    variation = torch.norm(curr_state - prev_state).item()
                    state_variations.append(variation)
            
            decision_complexity = sum(state_variations) / len(state_variations) if state_variations else 0
        else:
            decision_complexity = 0
        
        # Generate reasoning steps
        reasoning_steps = [
            "Analyze current architectural state",
            "Identify key decision factors",
            "Evaluate alternative approaches",
            "Consider trade-offs and constraints",
            "Synthesize recommendation"
        ]
        
        return {
            'reasoning_depth': reasoning_depth,
            'decision_complexity': decision_complexity,
            'reasoning_steps': reasoning_steps,
            'confidence': min(reasoning_depth / 5.0, 1.0)  # Max confidence at 5+ steps
        }
    
    def _generate_architectural_advice(
        self,
        question: str,
        context: Optional[ArchitecturalContext],
        reasoning_analysis: Dict[str, Any]
    ) -> ArchitecturalAdvice:
        """Generate comprehensive architectural advice"""
        
        # Analyze the question type
        question_type = self._classify_question(question)
        
        # Generate context-aware analysis
        analysis = self._generate_analysis(question, question_type, context)
        
        # Generate recommendations
        recommendations = self._generate_recommendations(question_type, context)
        
        # Identify trade-offs
        trade_offs = self._identify_trade_offs(question_type, context)
        
        # Create implementation steps
        implementation_steps = self._generate_implementation_steps(question_type, context)
        
        # Suggest alternatives
        alternatives = self._generate_alternatives(question_type, context)
        
        return ArchitecturalAdvice(
            question=question,
            analysis=analysis,
            recommendations=recommendations,
            trade_offs=trade_offs,
            implementation_steps=implementation_steps,
            reasoning_process=reasoning_analysis['reasoning_steps'],
            confidence=reasoning_analysis['confidence'],
            alternative_approaches=alternatives
        )
    
    def _classify_question(self, question: str) -> str:
        """Classify the type of architectural question"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['refactor', 'restructure', 'redesign']):
            return 'refactoring'
        elif any(word in question_lower for word in ['integrate', 'connect', 'combine']):
            return 'integration'
        elif any(word in question_lower for word in ['performance', 'speed', 'optimize']):
            return 'performance'
        elif any(word in question_lower for word in ['scale', 'grow', 'expand']):
            return 'scalability'
        elif any(word in question_lower for word in ['pattern', 'design', 'structure']):
            return 'design_pattern'
        else:
            return 'general'
    
    def _generate_analysis(
        self, 
        question: str, 
        question_type: str, 
        context: Optional[ArchitecturalContext]
    ) -> str:
        """Generate contextual analysis of the architectural question"""
        
        analysis_parts = [
            f"**Question Analysis**: {question}",
            f"**Question Type**: {question_type.replace('_', ' ').title()}",
        ]
        
        if context:
            analysis_parts.extend([
                f"**Current Domain**: {context.domain.title()}",
                f"**Existing Patterns**: {', '.join(context.current_structure.get('patterns', ['None detected']))}",
                f"**Key Constraints**: {', '.join(context.constraints) if context.constraints else 'None identified'}",
                f"**Complexity Factors**: {', '.join(context.complexity_factors) if context.complexity_factors else 'Low complexity'}"
            ])
        
        # Add question-specific analysis
        if question_type == 'refactoring':
            analysis_parts.append("**Refactoring Considerations**: This involves restructuring existing code while preserving functionality. Key focus areas should be reducing coupling, improving cohesion, and maintaining domain boundaries.")
        elif question_type == 'integration':
            analysis_parts.append("**Integration Considerations**: This requires careful attention to interface design, error handling, and data consistency across system boundaries.")
        elif question_type == 'performance':
            analysis_parts.append("**Performance Considerations**: Focus on identifying bottlenecks, optimizing critical paths, and balancing performance with maintainability.")
        
        return '\n'.join(analysis_parts)
    
    def _generate_recommendations(
        self, 
        question_type: str, 
        context: Optional[ArchitecturalContext]
    ) -> List[str]:
        """Generate specific recommendations based on question type and context"""
        
        base_recommendations = {
            'refactoring': [
                "Start with comprehensive test coverage before refactoring",
                "Identify and extract common functionality into shared services",
                "Maintain domain boundaries and avoid cross-domain dependencies",
                "Use the strangler pattern for gradual migration"
            ],
            'integration': [
                "Design clear interfaces and contracts between components",
                "Implement proper error handling and circuit breakers",
                "Use event-driven patterns for loose coupling",
                "Add comprehensive monitoring and logging"
            ],
            'performance': [
                "Profile the system to identify actual bottlenecks",
                "Implement caching at appropriate layers",
                "Consider database query optimization",
                "Use asynchronous processing for non-critical operations"
            ],
            'scalability': [
                "Design for horizontal scaling from the start",
                "Implement proper database sharding or read replicas",
                "Use message queues for decoupling and load distribution",
                "Consider microservices for independent scaling"
            ],
            'design_pattern': [
                "Choose patterns that fit your specific use case",
                "Consider the trade-offs of each pattern",
                "Ensure team understanding and documentation",
                "Start simple and evolve as needed"
            ]
        }
        
        recommendations = base_recommendations.get(question_type, [
            "Analyze current architecture thoroughly",
            "Consider multiple approaches and their trade-offs",
            "Start with minimal viable changes",
            "Measure impact and iterate"
        ])
        
        # Add context-specific recommendations
        if context:
            if context.domain == 'trading':
                recommendations.append("Ensure low-latency requirements are met for trading operations")
                recommendations.append("Implement proper risk management and transaction consistency")
            elif context.domain == 'gamification':
                recommendations.append("Design for real-time updates and user engagement")
                recommendations.append("Consider eventual consistency for non-critical game state")
        
        return recommendations
    
    def _identify_trade_offs(
        self, 
        question_type: str, 
        context: Optional[ArchitecturalContext]
    ) -> List[Dict[str, str]]:
        """Identify key trade-offs for the architectural decision"""
        
        common_trade_offs = [
            {
                "aspect": "Complexity vs Maintainability",
                "description": "More sophisticated solutions may be harder to maintain",
                "recommendation": "Choose the simplest solution that meets requirements"
            },
            {
                "aspect": "Performance vs Flexibility", 
                "description": "Highly optimized solutions may be less adaptable",
                "recommendation": "Optimize critical paths while keeping flexibility elsewhere"
            },
            {
                "aspect": "Development Speed vs Quality",
                "description": "Quick solutions may accumulate technical debt",
                "recommendation": "Balance delivery pressure with long-term maintainability"
            }
        ]
        
        if question_type == 'integration':
            common_trade_offs.append({
                "aspect": "Coupling vs Performance",
                "description": "Looser coupling may introduce latency overhead",
                "recommendation": "Use async patterns where latency is not critical"
            })
        
        return common_trade_offs
    
    def _generate_implementation_steps(
        self, 
        question_type: str, 
        context: Optional[ArchitecturalContext]
    ) -> List[str]:
        """Generate step-by-step implementation guidance"""
        
        base_steps = {
            'refactoring': [
                "1. Create comprehensive test suite for existing functionality",
                "2. Identify extraction boundaries and create interfaces",
                "3. Extract common functionality to shared modules",
                "4. Update calling code to use new interfaces",
                "5. Remove duplicate code and clean up",
                "6. Verify all tests pass and performance is maintained"
            ],
            'integration': [
                "1. Define integration contracts and interfaces",
                "2. Implement integration adapters with error handling",
                "3. Set up monitoring and alerting",
                "4. Create integration tests",
                "5. Deploy with feature flags for safe rollout",
                "6. Monitor and optimize based on real usage"
            ],
            'performance': [
                "1. Establish performance baselines and metrics",
                "2. Profile application to identify bottlenecks",
                "3. Implement targeted optimizations",
                "4. Add performance monitoring",
                "5. Load test optimizations",
                "6. Document performance characteristics"
            ]
        }
        
        return base_steps.get(question_type, [
            "1. Analyze current state and requirements",
            "2. Design solution with clear interfaces",
            "3. Implement incrementally with testing",
            "4. Deploy with monitoring and rollback plan",
            "5. Measure impact and iterate"
        ])
    
    def _generate_alternatives(
        self, 
        question_type: str, 
        context: Optional[ArchitecturalContext]
    ) -> List[str]:
        """Generate alternative approaches to consider"""
        
        alternatives = {
            'refactoring': [
                "Big bang refactoring (higher risk, faster completion)",
                "Strangler pattern (gradual replacement)",
                "Branch by abstraction (parallel development)",
                "Extract service (microservices approach)"
            ],
            'integration': [
                "Direct API calls (tight coupling, low latency)",
                "Message queues (loose coupling, higher latency)",
                "Event sourcing (complete audit trail)",
                "Database-level integration (shared data)"
            ],
            'performance': [
                "Vertical scaling (simpler, limited)", 
                "Horizontal scaling (complex, unlimited)",
                "Caching layers (faster reads, consistency issues)",
                "Database optimization (focused improvements)"
            ]
        }
        
        return alternatives.get(question_type, [
            "Incremental approach (lower risk)",
            "Revolutionary approach (higher impact)",
            "Hybrid solution (balanced trade-offs)"
        ])
    
    def _format_advice(self, advice: ArchitecturalAdvice) -> str:
        """Format architectural advice for display"""
        
        sections = [
            f"# Architectural Advice",
            f"\n**Question**: {advice.question}",
            f"\n## Analysis\n{advice.analysis}",
            f"\n## Recommendations",
        ]
        
        for i, rec in enumerate(advice.recommendations, 1):
            sections.append(f"{i}. {rec}")
        
        sections.extend([
            f"\n## Implementation Steps",
        ])
        
        for step in advice.implementation_steps:
            sections.append(step)
        
        sections.extend([
            f"\n## Key Trade-offs",
        ])
        
        for trade_off in advice.trade_offs:
            sections.extend([
                f"### {trade_off['aspect']}",
                f"**Issue**: {trade_off['description']}",
                f"**Recommendation**: {trade_off['recommendation']}\n"
            ])
        
        sections.extend([
            f"## Alternative Approaches",
        ])
        
        for i, alt in enumerate(advice.alternative_approaches, 1):
            sections.append(f"{i}. {alt}")
        
        sections.extend([
            f"\n## Reasoning Process",
        ])
        
        for i, step in enumerate(advice.reasoning_process, 1):
            sections.append(f"{i}. {step}")
        
        sections.append(f"\n**Confidence Level**: {advice.confidence:.1%}")
        
        return '\n'.join(sections)